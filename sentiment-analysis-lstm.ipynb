{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9107347,"sourceType":"datasetVersion","datasetId":5496472}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T16:20:29.848528Z","iopub.execute_input":"2024-11-15T16:20:29.848840Z","iopub.status.idle":"2024-11-15T16:20:29.855451Z","shell.execute_reply.started":"2024-11-15T16:20:29.848808Z","shell.execute_reply":"2024-11-15T16:20:29.854542Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sentimenttraindataset/train_2kmZucJ.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sentimenttraindataset/train_2kmZucJ.csv')\ndf.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T16:20:32.844272Z","iopub.execute_input":"2024-11-15T16:20:32.844636Z","iopub.status.idle":"2024-11-15T16:20:32.881449Z","shell.execute_reply.started":"2024-11-15T16:20:32.844597Z","shell.execute_reply":"2024-11-15T16:20:32.880550Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        id  label                                              tweet\n2834  2835      0  Love kisses customized case for the iphone 3 f...\n6838  6839      0  99% #lowfat #yogurt #apple and peach #yogurt #...\n1155  1156      0  Gain Followers RT This MUST FOLLOW ME I FOLLOW...\n1655  1656      0  When dreams come true. #macbook #macbookpro #a...\n1134  1135      0  Listening to #win #god #iphone #android #ps3 #...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2834</th>\n      <td>2835</td>\n      <td>0</td>\n      <td>Love kisses customized case for the iphone 3 f...</td>\n    </tr>\n    <tr>\n      <th>6838</th>\n      <td>6839</td>\n      <td>0</td>\n      <td>99% #lowfat #yogurt #apple and peach #yogurt #...</td>\n    </tr>\n    <tr>\n      <th>1155</th>\n      <td>1156</td>\n      <td>0</td>\n      <td>Gain Followers RT This MUST FOLLOW ME I FOLLOW...</td>\n    </tr>\n    <tr>\n      <th>1655</th>\n      <td>1656</td>\n      <td>0</td>\n      <td>When dreams come true. #macbook #macbookpro #a...</td>\n    </tr>\n    <tr>\n      <th>1134</th>\n      <td>1135</td>\n      <td>0</td>\n      <td>Listening to #win #god #iphone #android #ps3 #...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from IPython.core.display import HTML\nHTML(df.sample(10).to_html(index=False))","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:34.240833Z","iopub.execute_input":"2024-11-15T16:20:34.241286Z","iopub.status.idle":"2024-11-15T16:20:34.250389Z","shell.execute_reply.started":"2024-11-15T16:20:34.241241Z","shell.execute_reply":"2024-11-15T16:20:34.249411Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>738</td>\n      <td>0</td>\n      <td>Me n my bridesmaid #white #wedding #iphone #instagram #bride #bridesmaid #memories #memory #forever o http://instagr.am/p/RAxoBXPKWI/</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>0</td>\n      <td>My second DIY phone case Just a tad proud ;) #iphone #iphonecase #case #diy #blue #purple #me http://instagram.com/p/bCLdaMxBE_/</td>\n    </tr>\n    <tr>\n      <td>3878</td>\n      <td>0</td>\n      <td>#post #apple #dtm #share #sexy #lingerie #woman #porno #breast #speedway #boobs #$&amp;@*# #real #new Sexy Girls==&amp;gt; http://bit.ly/LUQ5nw</td>\n    </tr>\n    <tr>\n      <td>4236</td>\n      <td>1</td>\n      <td>Get my back fixe on my iphone and drop it a cracked it already #cheep rself #apple #$&amp;@*# #merked</td>\n    </tr>\n    <tr>\n      <td>3120</td>\n      <td>1</td>\n      <td>.@MacWorld Loving my #iPad EXCEPT for fact it won't play videos from 1/2 the sites I visit as I can't use #Adobe Flash! MAJOR . #Apple!</td>\n    </tr>\n    <tr>\n      <td>5636</td>\n      <td>0</td>\n      <td>Ahhh i'm so lucky! :3 #laptop #mac #macbookpro #apple #pretty #new #excited http://instagr.am/p/PKC66zjdWD/</td>\n    </tr>\n    <tr>\n      <td>4174</td>\n      <td>0</td>\n      <td>Got this from #samsung hahaha it was free.. me likeyy♡ #free #handphone #samsung #purple #android #in http://instagr.am/p/OJadRKkoke/</td>\n    </tr>\n    <tr>\n      <td>3358</td>\n      <td>0</td>\n      <td>@TeambringitMike iTunes stores are quite the guys at that aren't they.</td>\n    </tr>\n    <tr>\n      <td>4037</td>\n      <td>0</td>\n      <td>Road to platino #Danganronpa #Trigger #Havoc #Platino #PsVita #Sony #Trofei http://instagram.com/p/xUDBQvlycn/</td>\n    </tr>\n    <tr>\n      <td>4565</td>\n      <td>0</td>\n      <td>Just for fun #instagram #instafun #funny #myself #me #android #samsung #androidnesia http://instagram.com/p/XR_7BXijsr/</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df = df.drop(columns=['id'])\ndf.head(15)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:35.411516Z","iopub.execute_input":"2024-11-15T16:20:35.412250Z","iopub.status.idle":"2024-11-15T16:20:35.423426Z","shell.execute_reply.started":"2024-11-15T16:20:35.412211Z","shell.execute_reply":"2024-11-15T16:20:35.422494Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"    label                                              tweet\n0       0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n1       0  Finally a transparant silicon case ^^ Thanks t...\n2       0  We love this! Would you go? #talk #makememorie...\n3       0  I'm wired I know I'm George I was made that wa...\n4       1  What amazing service! Apple won't even talk to...\n5       1  iPhone software update fucked up my phone big ...\n6       0  Happy for us .. #instapic #instadaily #us #son...\n7       0  New Type C charger cable #UK http://www.ebay.c...\n8       0  Bout to go shopping again listening to music #...\n9       0  Photo: #fun #selfie #pool #water #sony #camera...\n10      1  hey #apple when you make a new ipod dont make ...\n11      1  Ha! Not heavy machinery but it does what I nee...\n12      1  Contemplating giving in to the iPhone bandwago...\n13      0  I just made another crazy purchase lol my theo...\n14      1  @shaqlockholmes @sam_louise1991 the battery is...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>We love this! Would you go? #talk #makememorie...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>I'm wired I know I'm George I was made that wa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>What amazing service! Apple won't even talk to...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>iPhone software update fucked up my phone big ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>Happy for us .. #instapic #instadaily #us #son...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>New Type C charger cable #UK http://www.ebay.c...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>Bout to go shopping again listening to music #...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>Photo: #fun #selfie #pool #water #sony #camera...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>hey #apple when you make a new ipod dont make ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>Ha! Not heavy machinery but it does what I nee...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>Contemplating giving in to the iPhone bandwago...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>I just made another crazy purchase lol my theo...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>@shaqlockholmes @sam_louise1991 the battery is...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# lowercasing\ndf['tweet'] = df['tweet'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:36.644104Z","iopub.execute_input":"2024-11-15T16:20:36.644987Z","iopub.status.idle":"2024-11-15T16:20:36.658325Z","shell.execute_reply.started":"2024-11-15T16:20:36.644942Z","shell.execute_reply":"2024-11-15T16:20:36.657255Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# remove URL\nimport re\ndef remove_url(text):\n    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return pattern.sub(r'',text)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:37.910413Z","iopub.execute_input":"2024-11-15T16:20:37.910786Z","iopub.status.idle":"2024-11-15T16:20:37.915500Z","shell.execute_reply.started":"2024-11-15T16:20:37.910749Z","shell.execute_reply":"2024-11-15T16:20:37.914560Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df['tweet']=df['tweet'].apply(remove_url)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:38.965566Z","iopub.execute_input":"2024-11-15T16:20:38.965924Z","iopub.status.idle":"2024-11-15T16:20:39.006831Z","shell.execute_reply.started":"2024-11-15T16:20:38.965885Z","shell.execute_reply":"2024-11-15T16:20:39.006050Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Remove Hashtags\nimport re\ndef remove_hashtags(text):\n    return re.sub(r'#\\w*', '', text)\ndf['tweet'] = df['tweet'].apply(remove_hashtags)\nprint(df['tweet'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T16:20:39.952187Z","iopub.execute_input":"2024-11-15T16:20:39.952517Z","iopub.status.idle":"2024-11-15T16:20:39.992269Z","shell.execute_reply.started":"2024-11-15T16:20:39.952482Z","shell.execute_reply":"2024-11-15T16:20:39.991264Z"}},"outputs":[{"name":"stdout","text":"0                                          test          \n1       finally a transparant silicon case ^^ thanks t...\n2                 we love this! would you go?        ... \n3       i'm wired i know i'm george i was made that wa...\n4       what amazing service! apple won't even talk to...\n                              ...                        \n7915                                live out loud        \n7916    we would like to wish you an amazing day! make...\n7917    helping my lovely 90 year old neighbor with he...\n7918    finally got my    stay connected anytime,anywh...\n7919                       apple barcelona!!!          … \nName: tweet, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"contractions_dict = {\n    \"i'm\": \"I am\",\n    \"you're\": \"you are\",\n    \"he's\": \"he is\",\n    \"she's\": \"she is\",\n    \"it's\": \"it is\",\n    \"we're\": \"we are\",\n    \"they're\": \"they are\",\n    \"don't\": \"do not\",\n    \"doesn't\": \"does not\",\n    \"can't\": \"cannot\",\n    \"couldn't\": \"could not\",\n    \"shouldn't\": \"should not\",\n    \"wouldn't\": \"would not\",\n    \"haven't\": \"have not\",\n    \"hasn't\": \"has not\",\n    \"hadn't\": \"had not\",\n    \"won't\": \"will not\",\n    \"would've\": \"would have\",\n    \"might've\": \"might have\",\n    \"must've\": \"must have\",\n    \"shan't\": \"shall not\",\n    \"let's\": \"let us\",\n    \"o'clock\": \"of the clock\",\n    \"y'all\": \"you all\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T16:20:41.127639Z","iopub.execute_input":"2024-11-15T16:20:41.128034Z","iopub.status.idle":"2024-11-15T16:20:41.134180Z","shell.execute_reply.started":"2024-11-15T16:20:41.127996Z","shell.execute_reply":"2024-11-15T16:20:41.132999Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import re\ndef expand_contractions(text):\n    # Replace contractions in the text\n    pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b', re.IGNORECASE)\n    expanded_text = pattern.sub(lambda x: contractions_dict[x.group(0).lower()], text)\n    \n    return expanded_text\n\n# Exam/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T16:20:42.612804Z","iopub.execute_input":"2024-11-15T16:20:42.613167Z","iopub.status.idle":"2024-11-15T16:20:42.619653Z","shell.execute_reply.started":"2024-11-15T16:20:42.613131Z","shell.execute_reply":"2024-11-15T16:20:42.618746Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df['tweet'] = df['tweet'].apply(expand_contractions)\ndf['tweet']","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:43.814034Z","iopub.execute_input":"2024-11-15T16:20:43.814383Z","iopub.status.idle":"2024-11-15T16:20:43.967391Z","shell.execute_reply.started":"2024-11-15T16:20:43.814347Z","shell.execute_reply":"2024-11-15T16:20:43.966435Z"},"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0                                          test          \n1       finally a transparant silicon case ^^ thanks t...\n2                 we love this! would you go?        ... \n3       I am wired i know I am george i was made that ...\n4       what amazing service! apple will not even talk...\n                              ...                        \n7915                                live out loud        \n7916    we would like to wish you an amazing day! make...\n7917    helping my lovely 90 year old neighbor with he...\n7918    finally got my    stay connected anytime,anywh...\n7919                       apple barcelona!!!          … \nName: tweet, Length: 7920, dtype: object"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Remove punctuation\nimport string \nexclude = string.punctuation\nexclude\ndef removePunc(text):\n    return text.translate(str.maketrans('','',exclude))\ndf['tweet']=df['tweet'].apply(removePunc)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:44.945293Z","iopub.execute_input":"2024-11-15T16:20:44.945639Z","iopub.status.idle":"2024-11-15T16:20:44.990033Z","shell.execute_reply.started":"2024-11-15T16:20:44.945603Z","shell.execute_reply":"2024-11-15T16:20:44.989050Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"HTML(df.head(5).to_html(index=False))","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:46.054245Z","iopub.execute_input":"2024-11-15T16:20:46.055025Z","iopub.status.idle":"2024-11-15T16:20:46.062748Z","shell.execute_reply.started":"2024-11-15T16:20:46.054985Z","shell.execute_reply":"2024-11-15T16:20:46.061817Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>finally a transparant silicon case  thanks to my uncle      …</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>we love this would you go</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>I am wired i know I am george i was made that way</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>what amazing service apple will not even talk to me about a question i have unless i pay them 1995 for their stupid support</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Tokenizer\nfrom nltk.tokenize import TweetTokenizer\ntknzr = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\ndf['tweet_tokens'] = df['tweet'].apply(tknzr.tokenize)\nprint(df['tweet_tokens'])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:47.108847Z","iopub.execute_input":"2024-11-15T16:20:47.109192Z","iopub.status.idle":"2024-11-15T16:20:49.012301Z","shell.execute_reply.started":"2024-11-15T16:20:47.109160Z","shell.execute_reply":"2024-11-15T16:20:49.011329Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                  [test]\n1       [finally, a, transparant, silicon, case, thank...\n2                        [we, love, this, would, you, go]\n3       [i, am, wired, i, know, i, am, george, i, was,...\n4       [what, amazing, service, apple, will, not, eve...\n                              ...                        \n7915                                    [live, out, loud]\n7916    [we, would, like, to, wish, you, an, amazing, ...\n7917    [helping, my, lovely, 90, year, old, neighbor,...\n7918    [finally, got, my, stay, connected, anytimeany...\n7919                                [apple, barcelona, …]\nName: tweet_tokens, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Remove Stop Words\nfrom nltk.corpus import stopwords\ncache_english_stopwords = stopwords.words('english')\ndf['tweet'] = df['tweet_tokens'].apply(lambda x: [i for i in x if i not in cache_english_stopwords])\nprint( df['tweet'])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:49.014165Z","iopub.execute_input":"2024-11-15T16:20:49.015021Z","iopub.status.idle":"2024-11-15T16:20:49.194318Z","shell.execute_reply.started":"2024-11-15T16:20:49.014974Z","shell.execute_reply":"2024-11-15T16:20:49.193383Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                  [test]\n1       [finally, transparant, silicon, case, thanks, ...\n2                                       [love, would, go]\n3                        [wired, know, george, made, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [helping, lovely, 90, year, old, neighbor, ipa...\n7918     [finally, got, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: tweet, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Filter the Data after Preprocess\ndf['tweet_filtered'] = df['tweet'].apply(lambda x: ' '.join(x))\nprint( df['tweet_filtered'])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:20:50.360841Z","iopub.execute_input":"2024-11-15T16:20:50.361556Z","iopub.status.idle":"2024-11-15T16:20:50.373923Z","shell.execute_reply.started":"2024-11-15T16:20:50.361515Z","shell.execute_reply":"2024-11-15T16:20:50.372857Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                    test\n1         finally transparant silicon case thanks uncle …\n2                                           love would go\n3                              wired know george made way\n4       amazing service apple even talk question unles...\n                              ...                        \n7915                                            live loud\n7916    would like wish amazing day make every minute ...\n7917    helping lovely 90 year old neighbor ipad morni...\n7918           finally got stay connected anytimeanywhere\n7919                                    apple barcelona …\nName: tweet_filtered, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from collections import Counter\nimport re\n\n# Vocabulary and probabilities\nvocabulary = {'example', 'condition', 'during', 'generation', 'modified', 'same', 'manner'}\nword_probabilities = {'example': 0.01, 'condition': 0.02, 'during': 0.03, 'generation': 0.01, \n                      'modified': 0.01, 'same': 0.02, 'manner': 0.01}\n\n# Edit distance functions\ndef edit1(word):\n    letters = 'abcdefghijklmnopqrstuvwxyz'\n    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n    deletes = [L + R[1:] for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n    inserts = [L + c + R for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edit2(word): \n    return (e2 for e1 in edit1(word) for e2 in edit1(e1))\n\n# Spelling correction function\ndef correct_spelling(word):\n    if word in vocabulary:\n        return word\n    suggestions = edit1(word) or edit2(word) or [word]\n    best_guesses = [w for w in suggestions if w in vocabulary]\n    return max(best_guesses, key=word_probabilities.get, default=word)\n\n# Apply correction\ndf['tweet_corrected'] = df['tweet'].apply(\n    lambda tokens: [correct_spelling(word) for word in tokens]\n)\n\nprint(df['tweet_corrected'])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:23:43.657621Z","iopub.execute_input":"2024-11-15T16:23:43.658047Z","iopub.status.idle":"2024-11-15T16:23:50.140177Z","shell.execute_reply.started":"2024-11-15T16:23:43.658008Z","shell.execute_reply":"2024-11-15T16:23:50.139192Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                  [test]\n1       [finally, transparant, silicon, case, thanks, ...\n2                                       [love, would, go]\n3                        [wired, know, george, made, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [helping, lovely, 90, year, old, neighbor, ipa...\n7918     [finally, got, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: tweet_corrected, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"print(df['tweet'])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:26:48.862618Z","iopub.execute_input":"2024-11-15T16:26:48.863026Z","iopub.status.idle":"2024-11-15T16:26:48.870924Z","shell.execute_reply.started":"2024-11-15T16:26:48.862988Z","shell.execute_reply":"2024-11-15T16:26:48.869758Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                  [test]\n1       [finally, transparant, silicon, case, thanks, ...\n2                                       [love, would, go]\n3                        [wired, know, george, made, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [helping, lovely, 90, year, old, neighbor, ipa...\n7918     [finally, got, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: tweet, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import spacy\nimport pandas as pd\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef lemmatize_words_spacy(words):\n    doc = nlp(\" \".join(words))\n    return [token.lemma_ for token in doc]\n\ndf['tweet_lemmatized'] = df['tweet'].apply(lemmatize_words_spacy)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:27:57.449365Z","iopub.execute_input":"2024-11-15T16:27:57.449942Z","iopub.status.idle":"2024-11-15T16:28:42.620165Z","shell.execute_reply.started":"2024-11-15T16:27:57.449902Z","shell.execute_reply":"2024-11-15T16:28:42.619320Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Display the DataFrame with lemmatized tweets\nprint(df['tweet'])\nprint(df['tweet_lemmatized'])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:28:42.622134Z","iopub.execute_input":"2024-11-15T16:28:42.622463Z","iopub.status.idle":"2024-11-15T16:28:42.633042Z","shell.execute_reply.started":"2024-11-15T16:28:42.622430Z","shell.execute_reply":"2024-11-15T16:28:42.632214Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                  [test]\n1       [finally, transparant, silicon, case, thanks, ...\n2                                       [love, would, go]\n3                        [wired, know, george, made, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [helping, lovely, 90, year, old, neighbor, ipa...\n7918     [finally, got, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: tweet, Length: 7920, dtype: object\n0                                                  [test]\n1       [finally, transparant, silicon, case, thank, u...\n2                                       [love, would, go]\n3                         [wire, know, george, make, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [help, lovely, 90, year, old, neighbor, ipad, ...\n7918     [finally, get, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: tweet_lemmatized, Length: 7920, dtype: object\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ndef lemmatize_chatwords(words):\n    doc = nlp(\" \".join(words))\n    return [token.lemma_ for token in doc]\n\ndf['chatwords_lemmatized'] = df['tweet_lemmatized'].apply(lemmatize_chatwords)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:28:49.193098Z","iopub.execute_input":"2024-11-15T16:28:49.193938Z","iopub.status.idle":"2024-11-15T16:29:33.156914Z","shell.execute_reply.started":"2024-11-15T16:28:49.193896Z","shell.execute_reply":"2024-11-15T16:29:33.156107Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Display the DataFrame with lemmatized chat words\nprint(df['tweet'])\nprint(df['chatwords_lemmatized'])\ndf['tweet'] = df['chatwords_lemmatized'];\ndf","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:30:12.439871Z","iopub.execute_input":"2024-11-15T16:30:12.440252Z","iopub.status.idle":"2024-11-15T16:30:12.482052Z","shell.execute_reply.started":"2024-11-15T16:30:12.440216Z","shell.execute_reply":"2024-11-15T16:30:12.481130Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0                                                  [test]\n1       [finally, transparant, silicon, case, thanks, ...\n2                                       [love, would, go]\n3                        [wired, know, george, made, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [helping, lovely, 90, year, old, neighbor, ipa...\n7918     [finally, got, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: tweet, Length: 7920, dtype: object\n0                                                  [test]\n1       [finally, transparant, silicon, case, thank, u...\n2                                       [love, would, go]\n3                         [wire, know, george, make, way]\n4       [amazing, service, apple, even, talk, question...\n                              ...                        \n7915                                         [live, loud]\n7916    [would, like, wish, amazing, day, make, every,...\n7917    [help, lovely, 90, year, old, neighbor, ipad, ...\n7918     [finally, get, stay, connected, anytimeanywhere]\n7919                                [apple, barcelona, …]\nName: chatwords_lemmatized, Length: 7920, dtype: object\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"      label                                              tweet  \\\n0         0                                             [test]   \n1         0  [finally, transparant, silicon, case, thank, u...   \n2         0                                  [love, would, go]   \n3         0                    [wire, know, george, make, way]   \n4         1  [amazing, service, apple, even, talk, question...   \n...     ...                                                ...   \n7915      0                                       [live, loud]   \n7916      0  [would, like, wish, amazing, day, make, every,...   \n7917      0  [help, lovely, 90, year, old, neighbor, ipad, ...   \n7918      0   [finally, get, stay, connected, anytimeanywhere]   \n7919      0                              [apple, barcelona, …]   \n\n                                           tweet_tokens  \\\n0                                                [test]   \n1     [finally, a, transparant, silicon, case, thank...   \n2                      [we, love, this, would, you, go]   \n3     [i, am, wired, i, know, i, am, george, i, was,...   \n4     [what, amazing, service, apple, will, not, eve...   \n...                                                 ...   \n7915                                  [live, out, loud]   \n7916  [we, would, like, to, wish, you, an, amazing, ...   \n7917  [helping, my, lovely, 90, year, old, neighbor,...   \n7918  [finally, got, my, stay, connected, anytimeany...   \n7919                              [apple, barcelona, …]   \n\n                                         tweet_filtered  \\\n0                                                  test   \n1       finally transparant silicon case thanks uncle …   \n2                                         love would go   \n3                            wired know george made way   \n4     amazing service apple even talk question unles...   \n...                                                 ...   \n7915                                          live loud   \n7916  would like wish amazing day make every minute ...   \n7917  helping lovely 90 year old neighbor ipad morni...   \n7918         finally got stay connected anytimeanywhere   \n7919                                  apple barcelona …   \n\n                                        tweet_corrected  \\\n0                                                [test]   \n1     [finally, transparant, silicon, case, thanks, ...   \n2                                     [love, would, go]   \n3                      [wired, know, george, made, way]   \n4     [amazing, service, apple, even, talk, question...   \n...                                                 ...   \n7915                                       [live, loud]   \n7916  [would, like, wish, amazing, day, make, every,...   \n7917  [helping, lovely, 90, year, old, neighbor, ipa...   \n7918   [finally, got, stay, connected, anytimeanywhere]   \n7919                              [apple, barcelona, …]   \n\n                                       tweet_lemmatized  \\\n0                                                [test]   \n1     [finally, transparant, silicon, case, thank, u...   \n2                                     [love, would, go]   \n3                       [wire, know, george, make, way]   \n4     [amazing, service, apple, even, talk, question...   \n...                                                 ...   \n7915                                       [live, loud]   \n7916  [would, like, wish, amazing, day, make, every,...   \n7917  [help, lovely, 90, year, old, neighbor, ipad, ...   \n7918   [finally, get, stay, connected, anytimeanywhere]   \n7919                              [apple, barcelona, …]   \n\n                                   chatwords_lemmatized  \n0                                                [test]  \n1     [finally, transparant, silicon, case, thank, u...  \n2                                     [love, would, go]  \n3                       [wire, know, george, make, way]  \n4     [amazing, service, apple, even, talk, question...  \n...                                                 ...  \n7915                                       [live, loud]  \n7916  [would, like, wish, amazing, day, make, every,...  \n7917  [help, lovely, 90, year, old, neighbor, ipad, ...  \n7918   [finally, get, stay, connected, anytimeanywhere]  \n7919                              [apple, barcelona, …]  \n\n[7920 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_tokens</th>\n      <th>tweet_filtered</th>\n      <th>tweet_corrected</th>\n      <th>tweet_lemmatized</th>\n      <th>chatwords_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[test]</td>\n      <td>[test]</td>\n      <td>test</td>\n      <td>[test]</td>\n      <td>[test]</td>\n      <td>[test]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>[finally, transparant, silicon, case, thank, u...</td>\n      <td>[finally, a, transparant, silicon, case, thank...</td>\n      <td>finally transparant silicon case thanks uncle …</td>\n      <td>[finally, transparant, silicon, case, thanks, ...</td>\n      <td>[finally, transparant, silicon, case, thank, u...</td>\n      <td>[finally, transparant, silicon, case, thank, u...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>[love, would, go]</td>\n      <td>[we, love, this, would, you, go]</td>\n      <td>love would go</td>\n      <td>[love, would, go]</td>\n      <td>[love, would, go]</td>\n      <td>[love, would, go]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>[wire, know, george, make, way]</td>\n      <td>[i, am, wired, i, know, i, am, george, i, was,...</td>\n      <td>wired know george made way</td>\n      <td>[wired, know, george, made, way]</td>\n      <td>[wire, know, george, make, way]</td>\n      <td>[wire, know, george, make, way]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>[amazing, service, apple, even, talk, question...</td>\n      <td>[what, amazing, service, apple, will, not, eve...</td>\n      <td>amazing service apple even talk question unles...</td>\n      <td>[amazing, service, apple, even, talk, question...</td>\n      <td>[amazing, service, apple, even, talk, question...</td>\n      <td>[amazing, service, apple, even, talk, question...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7915</th>\n      <td>0</td>\n      <td>[live, loud]</td>\n      <td>[live, out, loud]</td>\n      <td>live loud</td>\n      <td>[live, loud]</td>\n      <td>[live, loud]</td>\n      <td>[live, loud]</td>\n    </tr>\n    <tr>\n      <th>7916</th>\n      <td>0</td>\n      <td>[would, like, wish, amazing, day, make, every,...</td>\n      <td>[we, would, like, to, wish, you, an, amazing, ...</td>\n      <td>would like wish amazing day make every minute ...</td>\n      <td>[would, like, wish, amazing, day, make, every,...</td>\n      <td>[would, like, wish, amazing, day, make, every,...</td>\n      <td>[would, like, wish, amazing, day, make, every,...</td>\n    </tr>\n    <tr>\n      <th>7917</th>\n      <td>0</td>\n      <td>[help, lovely, 90, year, old, neighbor, ipad, ...</td>\n      <td>[helping, my, lovely, 90, year, old, neighbor,...</td>\n      <td>helping lovely 90 year old neighbor ipad morni...</td>\n      <td>[helping, lovely, 90, year, old, neighbor, ipa...</td>\n      <td>[help, lovely, 90, year, old, neighbor, ipad, ...</td>\n      <td>[help, lovely, 90, year, old, neighbor, ipad, ...</td>\n    </tr>\n    <tr>\n      <th>7918</th>\n      <td>0</td>\n      <td>[finally, get, stay, connected, anytimeanywhere]</td>\n      <td>[finally, got, my, stay, connected, anytimeany...</td>\n      <td>finally got stay connected anytimeanywhere</td>\n      <td>[finally, got, stay, connected, anytimeanywhere]</td>\n      <td>[finally, get, stay, connected, anytimeanywhere]</td>\n      <td>[finally, get, stay, connected, anytimeanywhere]</td>\n    </tr>\n    <tr>\n      <th>7919</th>\n      <td>0</td>\n      <td>[apple, barcelona, …]</td>\n      <td>[apple, barcelona, …]</td>\n      <td>apple barcelona …</td>\n      <td>[apple, barcelona, …]</td>\n      <td>[apple, barcelona, …]</td>\n      <td>[apple, barcelona, …]</td>\n    </tr>\n  </tbody>\n</table>\n<p>7920 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# Dropping the unnecessary columns\ndf.drop(columns=['tweet_tokens', 'tweet_filtered','tweet_corrected','tweet_lemmatized','chatwords_lemmatized'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:30:20.645285Z","iopub.execute_input":"2024-11-15T16:30:20.645917Z","iopub.status.idle":"2024-11-15T16:30:20.658035Z","shell.execute_reply.started":"2024-11-15T16:30:20.645878Z","shell.execute_reply":"2024-11-15T16:30:20.657114Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:30:27.612898Z","iopub.execute_input":"2024-11-15T16:30:27.613268Z","iopub.status.idle":"2024-11-15T16:30:27.627025Z","shell.execute_reply.started":"2024-11-15T16:30:27.613232Z","shell.execute_reply":"2024-11-15T16:30:27.626127Z"},"trusted":true},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"      label                                              tweet\n0         0                                             [test]\n1         0  [finally, transparant, silicon, case, thank, u...\n2         0                                  [love, would, go]\n3         0                    [wire, know, george, make, way]\n4         1  [amazing, service, apple, even, talk, question...\n...     ...                                                ...\n7915      0                                       [live, loud]\n7916      0  [would, like, wish, amazing, day, make, every,...\n7917      0  [help, lovely, 90, year, old, neighbor, ipad, ...\n7918      0   [finally, get, stay, connected, anytimeanywhere]\n7919      0                              [apple, barcelona, …]\n\n[7920 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[test]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>[finally, transparant, silicon, case, thank, u...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>[love, would, go]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>[wire, know, george, make, way]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>[amazing, service, apple, even, talk, question...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7915</th>\n      <td>0</td>\n      <td>[live, loud]</td>\n    </tr>\n    <tr>\n      <th>7916</th>\n      <td>0</td>\n      <td>[would, like, wish, amazing, day, make, every,...</td>\n    </tr>\n    <tr>\n      <th>7917</th>\n      <td>0</td>\n      <td>[help, lovely, 90, year, old, neighbor, ipad, ...</td>\n    </tr>\n    <tr>\n      <th>7918</th>\n      <td>0</td>\n      <td>[finally, get, stay, connected, anytimeanywhere]</td>\n    </tr>\n    <tr>\n      <th>7919</th>\n      <td>0</td>\n      <td>[apple, barcelona, …]</td>\n    </tr>\n  </tbody>\n</table>\n<p>7920 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# # Splitting the data into training, validation, and test sets\n# X = df['tweet']  # Features\n# y = df['label']  # Labels\n\n# # Split into 80% train + validation and 20% test\n# X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Split the 80% into 70% training and 10% validation\n# X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)\n\n# X_train, X_valid, X_test, y_train, y_valid, y_test","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:30:31.518932Z","iopub.execute_input":"2024-11-15T16:30:31.519302Z","iopub.status.idle":"2024-11-15T16:30:31.542887Z","shell.execute_reply.started":"2024-11-15T16:30:31.519267Z","shell.execute_reply":"2024-11-15T16:30:31.541926Z"},"trusted":true},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(7170    [care, cover, spend, enough, money, buying, th...\n 7542    [gain, follower, rt, must, follow, follow, bac...\n 1008                        [thank, followcheck, website]\n 2861                      [look, get, little, brother, …]\n 4148    [remove, group, text, everyone, update, iphone...\n                               ...                        \n 6537    [instapic, mimmoal, feb, 2016, take, …, pictwi...\n 1603    [lemme, get, straight, charger, suck, therefor...\n 4569                           [welcome, life, new, baby]\n 4784    [well, mypad, facebook, app, thing, tweet, com...\n 4047                   [worry, pictwittercom, 0wqftykprt]\n Name: tweet, Length: 5544, dtype: object,\n 6017    [like, share, want, diamond, case, iphone, 6, ...\n 7301                     [look, death, ya, know, serious]\n 6355                                   [happy, friday, …]\n 2155          [frustration, deal, novice, googler, video]\n 5298    [good, christmas, gift, could, ever, ask, love...\n                               ...                        \n 7124                                      [take, leoqlam]\n 7388       [actually, hate, io, 6, destroy, phone, apple]\n 1532    [gain, follower, rt, must, follow, follow, bac...\n 7708                                            [love, …]\n 2150    [dear, word, suggestion, winder, anyway, switc...\n Name: tweet, Length: 792, dtype: object,\n 4896                      [photo, cause, dress, today, ]\n 7539    [skullcandy, product, brutal, 1, headphone, al...\n 1677    [sunset, today, zeeland, samsung, mobile, s4, ...\n 1964    [god, playstation, share, feature, cut, clip, ...\n 3025                                      [awe, da, well]\n                               ...                        \n 1419                                 [15, today, meee, …]\n 3939                  [arualcampbell, nothing, rear, end]\n 7834    [use, new, last, 3, day, battery, big, time, 4...\n 5137    [robertwindon, can, not, fix, junk, apple, pow...\n 4434                                      [use, zooom, …]\n Name: tweet, Length: 1584, dtype: object,\n 7170    1\n 7542    0\n 1008    0\n 2861    0\n 4148    1\n        ..\n 6537    0\n 1603    1\n 4569    0\n 4784    1\n 4047    0\n Name: label, Length: 5544, dtype: int64,\n 6017    0\n 7301    0\n 6355    0\n 2155    0\n 5298    0\n        ..\n 7124    0\n 7388    1\n 1532    0\n 7708    0\n 2150    1\n Name: label, Length: 792, dtype: int64,\n 4896    0\n 7539    1\n 1677    0\n 1964    0\n 3025    0\n        ..\n 1419    0\n 3939    0\n 7834    1\n 5137    1\n 4434    0\n Name: label, Length: 1584, dtype: int64)"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"import pandas as pd\nfrom gensim.models import Word2Vec\n\nsentences = df['tweet'].tolist()\n# df = pd.DataFrame(sentences);","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:40:15.106845Z","iopub.execute_input":"2024-11-15T16:40:15.107281Z","iopub.status.idle":"2024-11-15T16:40:15.113044Z","shell.execute_reply.started":"2024-11-15T16:40:15.107242Z","shell.execute_reply":"2024-11-15T16:40:15.112072Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\n# Example of training Word2Vec\nword2vec_model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\nword2vec_model.train(sentences, total_examples=len(sentences), epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:40:16.584198Z","iopub.execute_input":"2024-11-15T16:40:16.584542Z","iopub.status.idle":"2024-11-15T16:40:17.770220Z","shell.execute_reply.started":"2024-11-15T16:40:16.584509Z","shell.execute_reply":"2024-11-15T16:40:17.769307Z"},"trusted":true},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(454086, 523680)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"word2vec_model.wv.similarity(w1='good',w2=\"bad\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:40:18.225906Z","iopub.execute_input":"2024-11-15T16:40:18.226222Z","iopub.status.idle":"2024-11-15T16:40:18.233331Z","shell.execute_reply.started":"2024-11-15T16:40:18.226191Z","shell.execute_reply":"2024-11-15T16:40:18.232373Z"},"trusted":true},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"0.9852862"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"import numpy as np\n\n#X_train, X_valid, X_test\n\n# Function to convert a sentence to a sequence of vectors\ndef sentence_to_vector(sentence, model, max_len):\n    sentence_vector = [model.wv[word] if word in model.wv else np.zeros(model.vector_size) for word in sentence]\n    return sentence_vector[:max_len] + [np.zeros(model.vector_size)] * (max_len - len(sentence_vector))\n\n# Set the maximum length for padding/truncating sentences\nmax_len = max(len(sentence) for sentence in sentences)\n\n# Convert the sentences in each dataset to vectors\nX_train_vec = np.array([sentence_to_vector(sentence, word2vec_model, max_len) for sentence in X_train])\nX_valid_vec = np.array([sentence_to_vector(sentence, word2vec_model, max_len) for sentence in X_valid])\nX_test_vec = np.array([sentence_to_vector(sentence, word2vec_model, max_len) for sentence in X_test])\n\n# Check the shape of the vectors\nprint(\"Shape of X_train_vec:\",  X_train_vec.shape)\nprint(\"Shape of X_valid_vec:\", X_valid_vec.shape)\nprint(\"Shape of X_test_vec:\", X_test_vec.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:40:19.782311Z","iopub.execute_input":"2024-11-15T16:40:19.782949Z","iopub.status.idle":"2024-11-15T16:40:20.153561Z","shell.execute_reply.started":"2024-11-15T16:40:19.782907Z","shell.execute_reply":"2024-11-15T16:40:20.152655Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Shape of X_train_vec: (5544, 33, 100)\nShape of X_valid_vec: (792, 33, 100)\nShape of X_test_vec: (1584, 33, 100)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import LSTM, Dense,Embedding\n\n# model = Sequential()\n# model.add(LSTM(100, input_shape=(X_train_vec.shape[1], X_train_vec.shape[2])))\n# model.add(Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# model.fit(X_train_vec, y_train, epochs=10, batch_size=64, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T16:40:41.915239Z","iopub.execute_input":"2024-11-15T16:40:41.915619Z","iopub.status.idle":"2024-11-15T16:40:41.920069Z","shell.execute_reply.started":"2024-11-15T16:40:41.915582Z","shell.execute_reply":"2024-11-15T16:40:41.919151Z"},"trusted":true},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\nimport numpy as np\n\n# Define the model\nmodel = Sequential()\nmodel.add(LSTM(100, input_shape=(X_train_vec.shape[1], X_train_vec.shape[2])))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X_train_vec, y_train, epochs=10, batch_size=64, validation_split=0.2)\n\n# Extract validation data used during training\nval_size = int(0.2 * len(X_train_vec))  # 20% validation split\nX_val = X_train_vec[-val_size:]\ny_val = y_train[-val_size:]\n\n# Predict probabilities and threshold them at 0.5\ny_pred_probs = model.predict(X_val)\ny_pred = np.round(y_pred_probs).astype(int)\n\n# Calculate metrics\naccuracy = accuracy_score(y_val, y_pred)\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_val, y_pred, average='binary')\n\n# Print metrics\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1-score: {f1_score:.4f}')\n\n# Alternatively, detailed classification report\nreport = classification_report(y_val, y_pred)\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T16:50:17.019334Z","iopub.execute_input":"2024-11-15T16:50:17.019973Z","iopub.status.idle":"2024-11-15T16:50:23.549651Z","shell.execute_reply.started":"2024-11-15T16:50:17.019931Z","shell.execute_reply":"2024-11-15T16:50:23.548749Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7972 - loss: 0.5335 - val_accuracy: 0.8431 - val_loss: 0.3449\nEpoch 2/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8478 - loss: 0.3434 - val_accuracy: 0.8494 - val_loss: 0.3329\nEpoch 3/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8437 - loss: 0.3482 - val_accuracy: 0.8566 - val_loss: 0.3258\nEpoch 4/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - loss: 0.3579 - val_accuracy: 0.8575 - val_loss: 0.3231\nEpoch 5/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8357 - loss: 0.3518 - val_accuracy: 0.8539 - val_loss: 0.3325\nEpoch 6/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8519 - loss: 0.3433 - val_accuracy: 0.8485 - val_loss: 0.3322\nEpoch 7/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8441 - loss: 0.3394 - val_accuracy: 0.8611 - val_loss: 0.3212\nEpoch 8/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8491 - loss: 0.3271 - val_accuracy: 0.8611 - val_loss: 0.3171\nEpoch 9/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8692 - loss: 0.3152 - val_accuracy: 0.8593 - val_loss: 0.3201\nEpoch 10/10\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.3212 - val_accuracy: 0.8602 - val_loss: 0.3173\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\nAccuracy: 0.8601\nPrecision: 0.7072\nRecall: 0.8188\nF1-score: 0.7589\n              precision    recall  f1-score   support\n\n           0       0.93      0.88      0.90       810\n           1       0.71      0.82      0.76       298\n\n    accuracy                           0.86      1108\n   macro avg       0.82      0.85      0.83      1108\nweighted avg       0.87      0.86      0.86      1108\n\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_acc = model.evaluate(X_test_vec, y_test)\nprint(f'Test Accuracy: {test_acc}')","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:05:29.473090Z","iopub.execute_input":"2024-11-15T17:05:29.473497Z","iopub.status.idle":"2024-11-15T17:05:29.721386Z","shell.execute_reply.started":"2024-11-15T17:05:29.473460Z","shell.execute_reply":"2024-11-15T17:05:29.720547Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.2949\nTest Accuracy: 0.8642676472663879\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, train_acc = model.evaluate(X_train_vec,y_train)\nprint(f'Test Accuracy: {train_acc}')","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:05:31.841538Z","iopub.execute_input":"2024-11-15T17:05:31.842242Z","iopub.status.idle":"2024-11-15T17:05:32.591066Z","shell.execute_reply.started":"2024-11-15T17:05:31.842200Z","shell.execute_reply":"2024-11-15T17:05:32.590164Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8542 - loss: 0.3178\nTest Accuracy: 0.8551587462425232\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# x = np.array(df['tweet'].values)\n# y = np.array(df[\"label\"].values)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T03:54:57.655150Z","iopub.execute_input":"2024-09-02T03:54:57.655463Z","iopub.status.idle":"2024-09-02T03:54:57.660362Z","shell.execute_reply.started":"2024-09-02T03:54:57.655431Z","shell.execute_reply":"2024-09-02T03:54:57.659449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T03:54:58.223507Z","iopub.execute_input":"2024-09-02T03:54:58.224374Z","iopub.status.idle":"2024-09-02T03:54:58.229916Z","shell.execute_reply.started":"2024-09-02T03:54:58.224332Z","shell.execute_reply":"2024-09-02T03:54:58.229006Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# x_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-02T03:54:58.984528Z","iopub.execute_input":"2024-09-02T03:54:58.985350Z","iopub.status.idle":"2024-09-02T03:54:58.991267Z","shell.execute_reply.started":"2024-09-02T03:54:58.985308Z","shell.execute_reply":"2024-09-02T03:54:58.990272Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = Sequential()\n# vocalbulary_size = 6336\n# embeded_vector_size = 35\n# max_length=100\n# model.add(Embedding(vocalbulary_size,embeded_vector_size,input_length=max_length))\n# model.add(LSTM(100))\n# model.add(Dense(1,activation=\"sigmoid\"))\n\n# model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"accuracy\"])\n\n# print(model.summary())\n# print(\"Model Creation Completed !\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}